{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1aa68c57",
      "metadata": {
        "papermill": {
          "duration": 0.006571,
          "end_time": "2023-06-12T21:09:35.041144",
          "exception": false,
          "start_time": "2023-06-12T21:09:35.034573",
          "status": "completed"
        },
        "tags": [],
        "id": "1aa68c57"
      },
      "source": [
        "<h1><center><b>NeutrinAI</b></center></h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7632526",
      "metadata": {
        "papermill": {
          "duration": 0.005529,
          "end_time": "2023-06-12T21:09:35.052837",
          "exception": false,
          "start_time": "2023-06-12T21:09:35.047308",
          "status": "completed"
        },
        "tags": [],
        "id": "f7632526"
      },
      "source": [
        "This is the final prototype after the development of this proyect called \"NeutrinAI\"\n",
        "\n",
        "It aims to identify from which direction the neutrinos detected by the neutrino observatory come from. When detection events can be located quickly enough, traditional telescopes are used to investigate short-lived neutrino sources, such as supernovae or gamma-ray bursts\n",
        "\n",
        "Because the sky is huge, better localization will not only associate neutrinos with sources, but also help partner observatories narrow their search space. With an average of three thousand events per second to process, it's hard to keep up with the flow of data using traditional methods. The intention is to quickly and accurately process a large number of events.\n",
        "\n",
        "If you want to upload your image you can clone this notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b70c71e",
      "metadata": {
        "papermill": {
          "duration": 0.005574,
          "end_time": "2023-06-12T21:09:35.064255",
          "exception": false,
          "start_time": "2023-06-12T21:09:35.058681",
          "status": "completed"
        },
        "tags": [],
        "id": "9b70c71e"
      },
      "source": [
        "# **Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15018fd2",
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2023-06-12T21:09:35.078395Z",
          "iopub.status.busy": "2023-06-12T21:09:35.077336Z",
          "iopub.status.idle": "2023-06-12T21:09:38.417651Z",
          "shell.execute_reply": "2023-06-12T21:09:38.416488Z"
        },
        "papermill": {
          "duration": 3.350506,
          "end_time": "2023-06-12T21:09:38.420519",
          "exception": false,
          "start_time": "2023-06-12T21:09:35.070013",
          "status": "completed"
        },
        "tags": [],
        "id": "15018fd2",
        "outputId": "b4221fb3-a84b-4071-9dbc-01d0bc6d8c0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataIO.py  Layers.py  Losses.py  Metrics.py  Utils.py  __init__.py\r\n"
          ]
        }
      ],
      "source": [
        "!mkdir ./Packages\n",
        "!cp /neutrinai-packages/*.py ./Packages\n",
        "!ls ./Packages/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff3eaf04",
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2023-06-12T21:09:38.436114Z",
          "iopub.status.busy": "2023-06-12T21:09:38.435188Z",
          "iopub.status.idle": "2023-06-12T21:09:50.843253Z",
          "shell.execute_reply": "2023-06-12T21:09:50.842264Z"
        },
        "papermill": {
          "duration": 12.419352,
          "end_time": "2023-06-12T21:09:50.846214",
          "exception": false,
          "start_time": "2023-06-12T21:09:38.426862",
          "status": "completed"
        },
        "tags": [],
        "id": "ff3eaf04",
        "outputId": "3086df91-612b-4b89-f5e0-5b270b024bd2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
            "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
            "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
            "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
            "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
            "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
          ]
        }
      ],
      "source": [
        "import os,random,time,gc,matplotlib as mpl,matplotlib.pyplot as plt, pandas as pd\n",
        "from tqdm import tqdm\n",
        "import numpy as np,pandas as pd,pyarrow.parquet as pq,pyarrow as pa,tensorflow as tf\n",
        "from Packages.Layers import GABlockResRNN, RSBlock\n",
        "from Packages.Losses import VonMisesFisher3DLoss\n",
        "from Packages.Metrics import AngularDistScore, angular_dist_score\n",
        "from Packages.Utils import GpuMemoryManagement\n",
        "from typing import List"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37d6c4f5",
      "metadata": {
        "papermill": {
          "duration": 0.005979,
          "end_time": "2023-06-12T21:09:50.858710",
          "exception": false,
          "start_time": "2023-06-12T21:09:50.852731",
          "status": "completed"
        },
        "tags": [],
        "id": "37d6c4f5"
      },
      "source": [
        "# **Sensor geometry**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f991ab16",
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2023-06-12T21:09:50.876392Z",
          "iopub.status.busy": "2023-06-12T21:09:50.875257Z",
          "iopub.status.idle": "2023-06-12T21:09:50.931993Z",
          "shell.execute_reply": "2023-06-12T21:09:50.930726Z"
        },
        "papermill": {
          "duration": 0.068351,
          "end_time": "2023-06-12T21:09:50.935387",
          "exception": false,
          "start_time": "2023-06-12T21:09:50.867036",
          "status": "completed"
        },
        "tags": [],
        "id": "f991ab16"
      },
      "outputs": [],
      "source": [
        "# sensor_geometry\n",
        "sensor_geometry_df = pd.read_csv(\"neutrinai-packages/sensor_geometry.csv\")\n",
        "\n",
        "# counts\n",
        "doms_per_string = 60\n",
        "string_num = 86\n",
        "\n",
        "# index\n",
        "outer_long_strings = np.concatenate([np.arange(0, 25), np.arange(27, 34), np.arange(37, 44), np.arange(46, 78)])\n",
        "inner_long_strings = np.array([25, 26, 34, 35, 36, 44, 45])\n",
        "inner_short_strings = np.array([78, 79, 80, 81, 82, 83, 84, 85])\n",
        "\n",
        "# known specs\n",
        "outer_xy_resolution = 125. / 2\n",
        "inner_xy_resolution = 70. / 2\n",
        "long_z_resolution = 17. / 2\n",
        "short_z_resolution = 7. / 2\n",
        "\n",
        "# evaluate error\n",
        "sensor_x = sensor_geometry_df.x\n",
        "sensor_y = sensor_geometry_df.y\n",
        "sensor_z = sensor_geometry_df.z\n",
        "sensor_r_err = np.ones(doms_per_string * string_num)\n",
        "sensor_z_err = np.ones(doms_per_string * string_num)\n",
        "\n",
        "# r-error\n",
        "for string_id in outer_long_strings:\n",
        "    sensor_r_err[string_id * doms_per_string:(string_id + 1) * doms_per_string] = outer_xy_resolution\n",
        "for string_id in np.concatenate([inner_long_strings, inner_short_strings]):\n",
        "    sensor_r_err[string_id * doms_per_string:(string_id + 1) * doms_per_string] = inner_xy_resolution\n",
        "\n",
        "# z-error\n",
        "for string_id in outer_long_strings:\n",
        "    sensor_z_err[string_id * doms_per_string:(string_id + 1) * doms_per_string] = long_z_resolution\n",
        "for string_id in np.concatenate([inner_long_strings, inner_short_strings]):\n",
        "    for dom_id in range(doms_per_string):\n",
        "        z = sensor_z[string_id * doms_per_string + dom_id]\n",
        "        if (z < -156.) or (z > 95.5 and z < 191.5):\n",
        "            sensor_z_err[string_id * doms_per_string + dom_id] = short_z_resolution\n",
        "        else:\n",
        "            sensor_z_err[string_id * doms_per_string + dom_id] = long_z_resolution\n",
        "# register\n",
        "sensor_geometry_df[\"r_err\"] = sensor_r_err\n",
        "sensor_geometry_df[\"z_err\"] = sensor_z_err"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "199a1a2a",
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2023-06-12T21:09:50.950818Z",
          "iopub.status.busy": "2023-06-12T21:09:50.950355Z",
          "iopub.status.idle": "2023-06-12T21:09:50.961211Z",
          "shell.execute_reply": "2023-06-12T21:09:50.959817Z"
        },
        "papermill": {
          "duration": 0.022258,
          "end_time": "2023-06-12T21:09:50.964227",
          "exception": false,
          "start_time": "2023-06-12T21:09:50.941969",
          "status": "completed"
        },
        "tags": [],
        "id": "199a1a2a",
        "outputId": "7bbcd4a3-94bd-4c25-87b8-01ae825b5988"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "t_valid_length:  6199.700247193777  ns\n"
          ]
        }
      ],
      "source": [
        "# detector constants\n",
        "c_const = 0.299792458  # speed of light [m/ns]\n",
        "\n",
        "x_min = sensor_x.min()\n",
        "x_max = sensor_x.max()\n",
        "y_min = sensor_y.min()\n",
        "y_max = sensor_y.max()\n",
        "z_min = sensor_z.min()\n",
        "z_max = sensor_z.max()\n",
        "\n",
        "detector_length = np.sqrt((x_max - x_min)**2 + (y_max - y_min)**2 + (z_max - z_min)**2)\n",
        "t_valid_length = detector_length / c_const\n",
        "\n",
        "print(\"t_valid_length: \", t_valid_length, \" ns\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9cdacd10",
      "metadata": {
        "papermill": {
          "duration": 0.00624,
          "end_time": "2023-06-12T21:09:50.977374",
          "exception": false,
          "start_time": "2023-06-12T21:09:50.971134",
          "status": "completed"
        },
        "tags": [],
        "id": "9cdacd10"
      },
      "source": [
        "# **Generator from parquet**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cfcd30f",
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2023-06-12T21:09:50.992813Z",
          "iopub.status.busy": "2023-06-12T21:09:50.992401Z",
          "iopub.status.idle": "2023-06-12T21:09:51.019656Z",
          "shell.execute_reply": "2023-06-12T21:09:51.018431Z"
        },
        "papermill": {
          "duration": 0.0387,
          "end_time": "2023-06-12T21:09:51.022627",
          "exception": false,
          "start_time": "2023-06-12T21:09:50.983927",
          "status": "completed"
        },
        "tags": [],
        "id": "8cfcd30f"
      },
      "outputs": [],
      "source": [
        "def generator_from_parquet(\n",
        "    meta_data_path,\n",
        "    data_path_header,\n",
        "    max_pulse_count: int=128,\n",
        "    max_batch_id: int=9999,\n",
        "):\n",
        "    # type conversion for tf\n",
        "    if type(meta_data_path) == bytes:\n",
        "        meta_data_path = str(meta_data_path, 'utf-8')\n",
        "    if type(data_path_header) == bytes:\n",
        "        data_path_header = str(data_path_header, 'utf-8')\n",
        "        \n",
        "    print(meta_data_path)\n",
        "    print(data_path_header)\n",
        "    \n",
        "    # read one batch\n",
        "    meta_data = pq.ParquetFile(meta_data_path)\n",
        "    for meta_batch in meta_data.iter_batches(batch_size=200000):\n",
        "        # batch meta data\n",
        "        batch_id = meta_batch[\"batch_id\"][0].as_py()\n",
        "        event_ids = meta_batch[\"event_id\"].to_numpy()\n",
        "        \n",
        "        if batch_id > max_batch_id:\n",
        "            print(\"Reached max_batch_id!\")\n",
        "            return\n",
        "        \n",
        "        # batch data\n",
        "        data_batch = pq.read_table(data_path_header + f\"{batch_id:d}.parquet\")\n",
        "        sensor_id = data_batch[\"sensor_id\"].combine_chunks().to_numpy()\n",
        "        time = data_batch[\"time\"].combine_chunks().to_numpy()\n",
        "        charge = data_batch[\"charge\"].combine_chunks().to_numpy()\n",
        "        auxiliary = data_batch[\"auxiliary\"].combine_chunks().to_numpy(False)\n",
        "        pulse_index = np.append(meta_batch[\"first_pulse_index\"].to_numpy(), [data_batch.num_rows])\n",
        "        \n",
        "        # read each event\n",
        "        for event_id, first_idx, last_idx in zip(event_ids, pulse_index[:-1], pulse_index[1:]):\n",
        "            event_time = time[first_idx:last_idx]\n",
        "            event_time = event_time - event_time.min()\n",
        "            event_charge = charge[first_idx:last_idx]\n",
        "            event_auxiliary = auxiliary[first_idx:last_idx]\n",
        "            event_x = sensor_geometry_df.x[sensor_id[first_idx:last_idx]].values\n",
        "            event_y = sensor_geometry_df.y[sensor_id[first_idx:last_idx]].values\n",
        "            event_z = sensor_geometry_df.z[sensor_id[first_idx:last_idx]].values\n",
        "            \n",
        "            dtype = [\n",
        "                (\"time\", \"float16\"),\n",
        "                (\"charge\", \"float16\"),\n",
        "                (\"auxiliary\", \"float16\"),\n",
        "                (\"x\", \"float16\"),\n",
        "                (\"y\", \"float16\"),\n",
        "                (\"z\", \"float16\"),\n",
        "                (\"rank\", \"short\")\n",
        "            ]\n",
        "            event_features = np.zeros(last_idx - first_idx, dtype)\n",
        "            event_features[\"time\"] = event_time\n",
        "            event_features[\"charge\"] = event_charge\n",
        "            event_features[\"auxiliary\"] = event_auxiliary\n",
        "            event_features[\"x\"] = event_x\n",
        "            event_features[\"y\"] = event_y\n",
        "            event_features[\"z\"] = event_z\n",
        "\n",
        "            # point picker\n",
        "            if len(event_x) > max_pulse_count:\n",
        "                # find valid time window\n",
        "                t_peak = event_features[\"time\"][event_features[\"charge\"].argmax()]\n",
        "                t_valid_min = t_peak - t_valid_length\n",
        "                t_valid_max = t_peak + t_valid_length\n",
        "                \n",
        "                # rank\n",
        "                t_valid = (event_features[\"time\"] > t_valid_min) * (event_features[\"time\"] < t_valid_max)\n",
        "                event_features[\"rank\"] = 2 * (1 - event_features[\"auxiliary\"]) + (t_valid)\n",
        "                \n",
        "                # sort by rank and charge\n",
        "                event_features = np.sort(event_features, order=[\"rank\", \"charge\"])\n",
        "                \n",
        "                # pick-up from backward\n",
        "                event_features = event_features[-max_pulse_count:]\n",
        "                \n",
        "                # resort by time\n",
        "                event_features = np.sort(event_features, order=\"time\")\n",
        "            \n",
        "            pulse_count = min(len(event_x), max_pulse_count)\n",
        "            \n",
        "            # yield\n",
        "            features = np.zeros((max_pulse_count, 6), dtype=\"float32\")\n",
        "            features[:pulse_count, 0] = (event_features[\"time\"] - event_features[\"time\"].min()).astype(\"float32\") / 1000.\n",
        "            features[:pulse_count, 1] = event_features[\"charge\"].astype(\"float32\") / 300.\n",
        "            features[:pulse_count, 2] = event_features[\"auxiliary\"].astype(\"float32\") * 1.\n",
        "            features[:pulse_count, 3] = event_features[\"x\"].astype(\"float32\") / 600.\n",
        "            features[:pulse_count, 4] = event_features[\"y\"].astype(\"float32\") / 600.\n",
        "            features[:pulse_count, 5] = event_features[\"z\"].astype(\"float32\") / 600.\n",
        "\n",
        "            features[:, :][features[:, 1] == 0.0] = 0.0  # for masking layer\n",
        "            \n",
        "            yield event_id, features\n",
        "        \n",
        "        # memory management\n",
        "        del auxiliary, charge, time, sensor_id, data_batch, pulse_index, event_id\n",
        "        _=gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "788a4141",
      "metadata": {
        "papermill": {
          "duration": 0.006237,
          "end_time": "2023-06-12T21:09:51.035689",
          "exception": false,
          "start_time": "2023-06-12T21:09:51.029452",
          "status": "completed"
        },
        "tags": [],
        "id": "788a4141"
      },
      "source": [
        "# **Model RSRNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "badc6ecb",
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2023-06-12T21:09:51.050966Z",
          "iopub.status.busy": "2023-06-12T21:09:51.050501Z",
          "iopub.status.idle": "2023-06-12T21:09:59.925677Z",
          "shell.execute_reply": "2023-06-12T21:09:59.924249Z"
        },
        "papermill": {
          "duration": 8.886102,
          "end_time": "2023-06-12T21:09:59.928376",
          "exception": false,
          "start_time": "2023-06-12T21:09:51.042274",
          "status": "completed"
        },
        "tags": [],
        "id": "badc6ecb",
        "outputId": "d3c8e482-6eaa-4276-bf7b-30e2be50dbb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"RSGRUDA_s3260114_s595_s756_s639_s585_s403_s158_s263_s756\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 128, 6)]     0           []                               \n",
            "                                                                                                  \n",
            " Masking (Masking)              (None, 128, 6)       0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " rs_block (RSBlock)             ((None, 128, 6),     6820        ['Masking[0][0]']                \n",
            "                                 (None, 128, 93))                                                 \n",
            "                                                                                                  \n",
            " rs_block_1 (RSBlock)           ((None, 128, 6),     9517        ['rs_block[0][0]',               \n",
            "                                 (None, 128, 93))                 'rs_block[0][1]']               \n",
            "                                                                                                  \n",
            " RNN_input (Concatenate)        (None, 128, 192)     0           ['Masking[0][0]',                \n",
            "                                                                  'rs_block[0][1]',               \n",
            "                                                                  'rs_block_1[0][1]']             \n",
            "                                                                                                  \n",
            " ga_block_res_rnn (GABlockResRN  (None, 3)           551299      ['RNN_input[0][0]']              \n",
            " N)                                                                                               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 567,636\n",
            "Trainable params: 566,768\n",
            "Non-trainable params: 868\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_dir = \"/neutrinai-packages/\"\n",
        "\n",
        "model_da_name = \"best_model\"\n",
        "model_da = tf.keras.models.load_model(\n",
        "    model_dir + model_da_name + \".h5\",\n",
        "    custom_objects={\n",
        "        \"VonMisesFisher3DLoss\": VonMisesFisher3DLoss,\n",
        "        \"AngularDistScore\": AngularDistScore,\n",
        "        \"RSBlock\": RSBlock,\n",
        "        \"GABlockResRNN\": GABlockResRNN,\n",
        "    },\n",
        ")\n",
        "model_da.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64e7ca46",
      "metadata": {
        "papermill": {
          "duration": 0.008983,
          "end_time": "2023-06-12T21:09:59.946675",
          "exception": false,
          "start_time": "2023-06-12T21:09:59.937692",
          "status": "completed"
        },
        "tags": [],
        "id": "64e7ca46"
      },
      "source": [
        "# **Input batch**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86909d31",
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2023-06-12T21:09:59.967628Z",
          "iopub.status.busy": "2023-06-12T21:09:59.967194Z",
          "iopub.status.idle": "2023-06-12T21:10:00.105879Z",
          "shell.execute_reply": "2023-06-12T21:10:00.104336Z"
        },
        "papermill": {
          "duration": 0.15205,
          "end_time": "2023-06-12T21:10:00.108247",
          "exception": false,
          "start_time": "2023-06-12T21:09:59.956197",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "03788a9b23cc4d268fe0c680cf5cc7ae"
          ]
        },
        "id": "86909d31",
        "outputId": "310416a1-9003-4a6c-ded9-7e32f2b6e1f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Upload your batch dataset here please\n",
            "================================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03788a9b23cc4d268fe0c680cf5cc7ae",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "FileUpload(value={}, accept='.parquet', description='Upload')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from ipywidgets import FileUpload\n",
        "upload = FileUpload(\n",
        "    accept='.parquet',  # Accepted file extension e.g. '.txt', '.pdf', 'image/*', 'image/*,.pdf'\n",
        "    multiple=False  # True to accept multiple files upload else False\n",
        ")\n",
        "print(\"Upload your batch dataset here please\")\n",
        "print(\"=\"*64)\n",
        "print(\"\")\n",
        "display(upload)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44c7d3e1",
      "metadata": {
        "papermill": {
          "duration": 0.009156,
          "end_time": "2023-06-12T21:10:00.126941",
          "exception": false,
          "start_time": "2023-06-12T21:10:00.117785",
          "status": "completed"
        },
        "tags": [],
        "id": "44c7d3e1"
      },
      "source": [
        "# **Input metadata**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5755050c",
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2023-06-12T21:10:00.148608Z",
          "iopub.status.busy": "2023-06-12T21:10:00.148126Z",
          "iopub.status.idle": "2023-06-12T21:10:00.162190Z",
          "shell.execute_reply": "2023-06-12T21:10:00.160951Z"
        },
        "papermill": {
          "duration": 0.029344,
          "end_time": "2023-06-12T21:10:00.166321",
          "exception": false,
          "start_time": "2023-06-12T21:10:00.136977",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "e472244fa50b4064a35f6beb38ef6182"
          ]
        },
        "id": "5755050c",
        "outputId": "f9b51f4b-e9ea-490e-8284-fa6fc5b69dfb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Upload your metadata dataset here please\n",
            "================================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e472244fa50b4064a35f6beb38ef6182",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "FileUpload(value={}, accept='.parquet', description='Upload')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "upload2 = FileUpload(\n",
        "    accept='.parquet',  # Accepted file extension e.g. '.txt', '.pdf', 'image/*', 'image/*,.pdf'\n",
        "    multiple=False  # True to accept multiple files upload else False\n",
        ")\n",
        "print(\"Upload your metadata dataset here please\")\n",
        "print(\"=\"*64)\n",
        "print(\"\")\n",
        "display(upload2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "189937f2",
      "metadata": {
        "papermill": {
          "duration": 0.009603,
          "end_time": "2023-06-12T21:10:00.186276",
          "exception": false,
          "start_time": "2023-06-12T21:10:00.176673",
          "status": "completed"
        },
        "tags": [],
        "id": "189937f2"
      },
      "source": [
        "# **Projecting the inference**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e8e7e6f",
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2023-06-12T21:10:00.211713Z",
          "iopub.status.busy": "2023-06-12T21:10:00.211209Z",
          "iopub.status.idle": "2023-06-12T21:10:11.376924Z",
          "shell.execute_reply": "2023-06-12T21:10:11.375056Z"
        },
        "papermill": {
          "duration": 11.18153,
          "end_time": "2023-06-12T21:10:11.379515",
          "exception": false,
          "start_time": "2023-06-12T21:10:00.197985",
          "status": "completed"
        },
        "tags": [],
        "id": "2e8e7e6f",
        "outputId": "1b6aadb1-c274-4c95-dcfa-f56d9686a712"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading sample data\n",
            "The filename is: /kaggle/input/neutrinai-sample/batch_661.parquet\n",
            "Loading sample data\n",
            "The filename is: /kaggle/input/neutrinai-sample/metadata.parquet\n",
            "One batch has 1562 steps\n",
            "/kaggle/input/neutrinai-sample/metadata.parquet\n",
            "/kaggle/input/neutrinai-sample/batch_\n",
            "      1gc collect:  62459\n",
            "CPU times: user 9.41 s, sys: 185 ms, total: 9.6 s\n",
            "Wall time: 11.1 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "file_name = \"\"\n",
        "meta_data_path = \"\"\n",
        "data_path_header = \"\"\n",
        "\n",
        "\n",
        "if len(upload.data) > 0:\n",
        "    with open(\"batch_661.parquet\", \"w+b\") as i:\n",
        "        i.write(upload.data[0]) \n",
        "    print(\"Saving loaded data\")\n",
        "    file_name = \"batch_661.parquet\"\n",
        "    data_path_header = \"batch_\"\n",
        "else:\n",
        "    print(\"Loading sample data\")\n",
        "    file_name = \"neutrinai-sample/batch_661.parquet\"\n",
        "    data_path_header = \"neutrinai-sample/batch_\"\n",
        "print(\"The filename is: \"+file_name)\n",
        "\n",
        "\n",
        "if len(upload2.data) > 0:\n",
        "    with open(\"metadata.parquet\", \"w+b\") as i:\n",
        "        i.write(upload2.data[0]) \n",
        "    print(\"Saving loaded data\")\n",
        "    file_name = \"metadata.parquet\"\n",
        "    meta_data_path = \"metadata.parquet\"\n",
        "else:\n",
        "    print(\"Loading sample data\")\n",
        "    file_name = \"neutrinai-sample/metadata.parquet\"\n",
        "    meta_data_path = \"neutrinai-sample/metadata.parquet\"\n",
        "print(\"The filename is: \"+file_name)\n",
        "\n",
        "\n",
        "max_batch_id = 99999\n",
        "batch_size = 128\n",
        "\n",
        "max_pulse_count = 128\n",
        "max_pulse_count_lite = 80\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "test_da_ds = tf.data.Dataset.from_generator(\n",
        "    generator_from_parquet,\n",
        "    args=[meta_data_path, data_path_header, max_pulse_count, max_batch_id],\n",
        "    output_types=(tf.int32, tf.float32),\n",
        "    output_shapes=((None), (max_pulse_count, 6)),\n",
        ")\n",
        "test_da_ds = test_da_ds.batch(batch_size).prefetch(AUTOTUNE)\n",
        "\n",
        "with open('pred_da.csv', 'w') as pred_csv:\n",
        "    pred_csv.write('event_id,pred_x,pred_y,pred_z\\n')\n",
        "\n",
        "with open('pred_lite.csv', 'w') as pred_csv:\n",
        "    pred_csv.write('event_id,pred_x,pred_y,pred_z,pulse\\n')\n",
        "\n",
        "steps_per_batch = np.ceil(200000 // batch_size)\n",
        "print(f\"One batch has {int(steps_per_batch):d} steps\")\n",
        "\n",
        "step = 0\n",
        "for batch_data in test_da_ds:\n",
        "    step += 1\n",
        "    print(f\"{step:7d}\", end=\"\")\n",
        "    if (step % 20 == 0) or (step % steps_per_batch == 0):\n",
        "        print()\n",
        "        \n",
        "    batch_event_id, batch_features = batch_data\n",
        "#     batch_features[:, :, :][batch_features[:, :, 1] == 0.0] = 0.0  # for masking\n",
        "    \n",
        "    test_pred = model_da.predict_on_batch(batch_features)\n",
        "    \n",
        "    with open('pred_da.csv', 'a') as pred_csv:\n",
        "        for event_id, pred_x, pred_y, pred_z in zip(batch_event_id, test_pred[:, 0], test_pred[:, 1], test_pred[:, 2]):\n",
        "            pred_csv.write(f\"{event_id:d},{pred_x:f},{pred_y:f},{pred_z:f}\\n\")\n",
        "    \n",
        "    del batch_event_id, batch_features, test_pred\n",
        "\n",
        "del model_da\n",
        "tf.keras.backend.clear_session()\n",
        "print(\"gc collect: \", gc.collect())\n",
        "\n",
        "# read predictions\n",
        "pred_da = pd.read_csv(\"pred_da.csv\")\n",
        "\n",
        "event_id = pred_da.event_id.values\n",
        "\n",
        "pred_da_x = pred_da.pred_x.values\n",
        "pred_da_y = pred_da.pred_y.values\n",
        "pred_da_z = pred_da.pred_z.values\n",
        "\n",
        "test_pred = np.zeros((len(pred_da_x), 3))\n",
        "\n",
        "test_pred[:, 0] = pred_da_x\n",
        "test_pred[:, 1] = pred_da_y\n",
        "test_pred[:, 2] = pred_da_z\n",
        "\n",
        "# convert to angle\n",
        "kappa_pred = np.linalg.norm(test_pred, axis=1)\n",
        "vec_x_pred = test_pred[:, 0] / kappa_pred\n",
        "vec_y_pred = test_pred[:, 1] / kappa_pred\n",
        "vec_z_pred = test_pred[:, 2] / kappa_pred\n",
        "az_pred = np.arctan2(vec_y_pred, vec_x_pred)\n",
        "az_pred = np.where(az_pred < 0, az_pred + 2*np.pi, az_pred)\n",
        "zen_pred = np.arccos(vec_z_pred)\n",
        "\n",
        "with open('results.csv', 'w') as results:\n",
        "    results.write('event_id,azimuth,zenith\\n')\n",
        "    \n",
        "with open('results.csv', 'a') as results:\n",
        "    for event, azimuth, zenith in zip(event_id, az_pred, zen_pred):\n",
        "        results.write(f\"{event:d},{azimuth:f},{zenith:f}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11ce480c",
      "metadata": {
        "papermill": {
          "duration": 0.00988,
          "end_time": "2023-06-12T21:10:11.399983",
          "exception": false,
          "start_time": "2023-06-12T21:10:11.390103",
          "status": "completed"
        },
        "tags": [],
        "id": "11ce480c"
      },
      "source": [
        "# **Results**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbb02b34",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-12T21:10:11.422923Z",
          "iopub.status.busy": "2023-06-12T21:10:11.422256Z",
          "iopub.status.idle": "2023-06-12T21:10:11.454839Z",
          "shell.execute_reply": "2023-06-12T21:10:11.453351Z"
        },
        "papermill": {
          "duration": 0.047668,
          "end_time": "2023-06-12T21:10:11.457922",
          "exception": false,
          "start_time": "2023-06-12T21:10:11.410254",
          "status": "completed"
        },
        "tags": [],
        "id": "fbb02b34",
        "outputId": "a8561555-3024-40b2-a7cc-13aa721e5ff4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>event_id</th>\n",
              "      <th>azimuth</th>\n",
              "      <th>zenith</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2092</td>\n",
              "      <td>0.722364</td>\n",
              "      <td>2.228424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7344</td>\n",
              "      <td>3.349625</td>\n",
              "      <td>2.529557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9482</td>\n",
              "      <td>4.703065</td>\n",
              "      <td>1.536413</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   event_id   azimuth    zenith\n",
              "0      2092  0.722364  2.228424\n",
              "1      7344  3.349625  2.529557\n",
              "2      9482  4.703065  1.536413"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df_results = pd.read_csv(\"results.csv\")\n",
        "display(df_results)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 53.875671,
      "end_time": "2023-06-12T21:10:14.612125",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2023-06-12T21:09:20.736454",
      "version": "2.4.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}